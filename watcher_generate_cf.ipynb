{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.df_loader import load_breast_cancer_df, load_diabetes_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.preprocessing import preprocess_df\n",
    "from utils.models import train_three_models, evaluation_test, save_three_models, load_three_models\n",
    "from utils.watcher import  generate_watcher_result, process_result\n",
    "\n",
    "from utils.save import save_result_as_csv\n",
    "\n",
    "### Disable TF2 and enable TF1 for alibi.\n",
    "tf.get_logger().setLevel(40) \n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "tf.keras.backend.clear_session()\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False\n",
    "\n",
    "\n",
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF version:  2.4.0-rc0\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#### Select dataset ####\n",
    "\n",
    "dataset_name = 'breast_cancer' # [adult, german, compas]\n",
    "\n",
    "if dataset_name == 'diabetes':\n",
    "    dataset_loading_fn = load_diabetes_df\n",
    "elif dataset_name == 'breast_cancer':\n",
    "    dataset_loading_fn = load_breast_cancer_df\n",
    "else:\n",
    "    raise Exception(\"Unsupported dataset\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#### Load datafram info.\n",
    "df_info = preprocess_df(dataset_loading_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### Seperate to train and test set.\n",
    "train_df, test_df = train_test_split(df_info.dummy_df, train_size=.8, random_state=seed, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "### Get training and testing array.\n",
    "X_train = np.array(train_df[df_info.ohe_feature_names])\n",
    "y_train = np.array(train_df[df_info.target_name])\n",
    "X_test = np.array(test_df[df_info.ohe_feature_names])\n",
    "y_test = np.array(test_df[df_info.target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Train models.\n",
    "models = train_three_models(X_train, y_train)\n",
    "\n",
    "## Save models.\n",
    "save_three_models(models, dataset_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 455 samples\n",
      "Epoch 1/20\n",
      "455/455 [==============================] - 0s 158us/sample - loss: 0.6891 - acc: 0.5890\n",
      "Epoch 2/20\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.6788 - acc: 0.8044\n",
      "Epoch 3/20\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.6660 - acc: 0.8198\n",
      "Epoch 4/20\n",
      "455/455 [==============================] - 0s 12us/sample - loss: 0.6482 - acc: 0.8462\n",
      "Epoch 5/20\n",
      "455/455 [==============================] - 0s 14us/sample - loss: 0.6256 - acc: 0.8703\n",
      "Epoch 6/20\n",
      "455/455 [==============================] - 0s 16us/sample - loss: 0.5986 - acc: 0.8835\n",
      "Epoch 7/20\n",
      "455/455 [==============================] - 0s 19us/sample - loss: 0.5632 - acc: 0.8901\n",
      "Epoch 8/20\n",
      "455/455 [==============================] - 0s 22us/sample - loss: 0.5237 - acc: 0.8791\n",
      "Epoch 9/20\n",
      "455/455 [==============================] - 0s 14us/sample - loss: 0.4768 - acc: 0.9011\n",
      "Epoch 10/20\n",
      "455/455 [==============================] - 0s 12us/sample - loss: 0.4313 - acc: 0.8901\n",
      "Epoch 11/20\n",
      "455/455 [==============================] - 0s 10us/sample - loss: 0.3830 - acc: 0.9055\n",
      "Epoch 12/20\n",
      "455/455 [==============================] - 0s 10us/sample - loss: 0.3405 - acc: 0.9143\n",
      "Epoch 13/20\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.3016 - acc: 0.9011\n",
      "Epoch 14/20\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.2716 - acc: 0.9143\n",
      "Epoch 15/20\n",
      "455/455 [==============================] - 0s 10us/sample - loss: 0.2467 - acc: 0.9121\n",
      "Epoch 16/20\n",
      "455/455 [==============================] - 0s 12us/sample - loss: 0.2257 - acc: 0.9253\n",
      "Epoch 17/20\n",
      "455/455 [==============================] - 0s 10us/sample - loss: 0.2095 - acc: 0.9275\n",
      "Epoch 18/20\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.2011 - acc: 0.9253\n",
      "Epoch 19/20\n",
      "455/455 [==============================] - 0s 9us/sample - loss: 0.1913 - acc: 0.9209\n",
      "Epoch 20/20\n",
      "455/455 [==============================] - 0s 10us/sample - loss: 0.1765 - acc: 0.9187\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "### Load models\n",
    "models = load_three_models(X_train.shape[-1], dataset_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jrhs/miniforge3/envs/tf_mac/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### Print out accuracy on testset.\n",
    "evaluation_test(models, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DT: [0.9737] | RF [0.9912] | NN [0.9737]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Watcher Counterfactual"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "### Setting up the CF generating amount.\n",
    "num_instances = 5\n",
    "num_cf_per_instance = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "### Generate CF\n",
    "results = generate_watcher_result(df_info, train_df, models, num_instances, num_cf_per_instance, X_train, X_test, y_test, max_iters=1000)\n",
    "result_dfs = process_result(results, df_info)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finding counterfactual for dt\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "Found CF\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "Found CF\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n",
      "Finding counterfactual for rfc\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "Found CF\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "Found CF\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n",
      "Finding counterfactual for nn\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "Found CF\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "Found CF\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "### Save result as file.\n",
    "save_result_as_csv(\"watcher\", dataset_name, result_dfs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result has been saved to ./results/watcher_breast_cancer\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_mac': conda)"
  },
  "interpreter": {
   "hash": "5c622353f32ef24c8d83e5c3e334107c074e82d7c3e8ca52c56b9fc900ce33e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}