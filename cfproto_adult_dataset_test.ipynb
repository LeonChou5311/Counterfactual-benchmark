{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from time import time\n",
    "from utils.df_loader import load_adult_df\n",
    "from utils.preprocessing import min_max_scale_numerical, remove_missing_values, inverse_dummy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from alibi.explainers import CounterFactualProto, CounterFactual\n",
    "from alibi_cf.utils import get_cat_vars_dict\n",
    "\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "tf.keras.backend.clear_session()\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False\n",
    "\n",
    "\n",
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF version:  2.4.0-rc0\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df, feature_names, numerical_cols, categorical_cols, columns_type, target_name, possible_outcomes = load_adult_df()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "scaled_df, scaler = min_max_scale_numerical(df, numerical_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "scaled_df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age         workclass  education      marital-status  \\\n",
       "0  0.301370         State-gov  Bachelors       Never-married   \n",
       "1  0.452055  Self-emp-not-inc  Bachelors  Married-civ-spouse   \n",
       "2  0.287671           Private    HS-grad            Divorced   \n",
       "3  0.493151           Private       11th  Married-civ-spouse   \n",
       "4  0.150685           Private  Bachelors  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male       0.02174   \n",
       "1    Exec-managerial        Husband  White    Male       0.00000   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male       0.00000   \n",
       "3  Handlers-cleaners        Husband  Black    Male       0.00000   \n",
       "4     Prof-specialty           Wife  Black  Female       0.00000   \n",
       "\n",
       "   capital-loss  hours-per-week native-country  class  \n",
       "0           0.0        0.397959  United-States  <=50K  \n",
       "1           0.0        0.122449  United-States  <=50K  \n",
       "2           0.0        0.397959  United-States  <=50K  \n",
       "3           0.0        0.397959  United-States  <=50K  \n",
       "4           0.0        0.397959           Cuba  <=50K  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dummy_df = pd.get_dummies(scaled_df, columns=  [ col for col in categorical_cols if col != target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### We should have this amount of input features.\n",
    "sum([len(scaled_df[col].unique()) for col in categorical_cols if col != target_name]) + len(numerical_cols)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# enconded_df, encoder_dict = label_encode(scaled_df, categorical_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "all_cat_ohe_cols = {}\n",
    "for c_col in categorical_cols:\n",
    "    if c_col != target_name:\n",
    "        all_cat_ohe_cols[c_col] = [ ohe_col for ohe_col in dummy_df.columns if ohe_col.startswith(c_col) and ohe_col != target_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "ohe_feature_names = [ col for col in dummy_df.columns if col != target_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dummy_df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age  capital-gain  capital-loss  hours-per-week  class  \\\n",
       "0  0.301370       0.02174           0.0        0.397959  <=50K   \n",
       "1  0.452055       0.00000           0.0        0.122449  <=50K   \n",
       "2  0.287671       0.00000           0.0        0.397959  <=50K   \n",
       "3  0.493151       0.00000           0.0        0.397959  <=50K   \n",
       "4  0.150685       0.00000           0.0        0.397959  <=50K   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      0                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-inc  ...  native-country_Portugal  \\\n",
       "0                  0                       0  ...                        0   \n",
       "1                  0                       0  ...                        0   \n",
       "2                  1                       0  ...                        0   \n",
       "3                  1                       0  ...                        0   \n",
       "4                  1                       0  ...                        0   \n",
       "\n",
       "   native-country_Puerto-Rico  native-country_Scotland  native-country_South  \\\n",
       "0                           0                        0                     0   \n",
       "1                           0                        0                     0   \n",
       "2                           0                        0                     0   \n",
       "3                           0                        0                     0   \n",
       "4                           0                        0                     0   \n",
       "\n",
       "   native-country_Taiwan  native-country_Thailand  \\\n",
       "0                      0                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        0   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             1   \n",
       "3                               0                             1   \n",
       "4                               0                             0   \n",
       "\n",
       "   native-country_Vietnam  native-country_Yugoslavia  \n",
       "0                       0                          0  \n",
       "1                       0                          0  \n",
       "2                       0                          0  \n",
       "3                       0                          0  \n",
       "4                       0                          0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "inverse_dummy(dummy_df, all_cat_ohe_cols).head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age  capital-gain  capital-loss  hours-per-week  class  \\\n",
       "0  0.301370       0.02174           0.0        0.397959  <=50K   \n",
       "1  0.452055       0.00000           0.0        0.122449  <=50K   \n",
       "2  0.287671       0.00000           0.0        0.397959  <=50K   \n",
       "3  0.493151       0.00000           0.0        0.397959  <=50K   \n",
       "4  0.150685       0.00000           0.0        0.397959  <=50K   \n",
       "\n",
       "          workclass  education      marital-status         occupation  \\\n",
       "0         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex native-country  \n",
       "0  Not-in-family  White    Male  United-States  \n",
       "1        Husband  White    Male  United-States  \n",
       "2  Not-in-family  White    Male  United-States  \n",
       "3        Husband  Black    Male  United-States  \n",
       "4           Wife  Black  Female           Cuba  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_label_encoder = LabelEncoder()\n",
    "dummy_df[target_name] = target_label_encoder.fit_transform(dummy_df[target_name])\n",
    "\n",
    "dummy_df= dummy_df[ohe_feature_names + [target_name]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_df, test_df = train_test_split(dummy_df, train_size=.8, random_state=seed, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_train = np.array(train_df[ohe_feature_names])\n",
    "y_train = np.array(train_df[target_name])\n",
    "X_test = np.array(test_df[ohe_feature_names])\n",
    "y_test = np.array(test_df[target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "### Train\n",
    "nn = model= tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(24,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(1),\n",
    "                tf.keras.layers.Activation(tf.nn.sigmoid),\n",
    "            ]\n",
    "        )\n",
    "nn.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn.fit(X_train, y_train, batch_size=64, epochs=20, shuffle=True)\n",
    "\n",
    "models = {\n",
    "    \"dt\": DecisionTreeClassifier().fit(X_train,y_train),\n",
    "    \"rfc\": RandomForestClassifier().fit(X_train,y_train),\n",
    "    \"nn\": nn,\n",
    "}\n",
    "\n",
    "pickle.dump(models['dt'], open('./saved_models/dt.p', 'wb'))\n",
    "pickle.dump(models['rfc'], open('./saved_models/rfc.p', 'wb'))\n",
    "models['nn'].save('./saved_models/nn.h5',overwrite=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 26048 samples\n",
      "Epoch 1/20\n",
      "26048/26048 [==============================] - 0s 8us/sample - loss: 0.4239 - acc: 0.8019\n",
      "Epoch 2/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3430 - acc: 0.8394\n",
      "Epoch 3/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3326 - acc: 0.8446\n",
      "Epoch 4/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3254 - acc: 0.8474\n",
      "Epoch 5/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3200 - acc: 0.8508\n",
      "Epoch 6/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3165 - acc: 0.8524\n",
      "Epoch 7/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3136 - acc: 0.8544\n",
      "Epoch 8/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3109 - acc: 0.8561\n",
      "Epoch 9/20\n",
      "26048/26048 [==============================] - 0s 7us/sample - loss: 0.3089 - acc: 0.8556\n",
      "Epoch 10/20\n",
      "26048/26048 [==============================] - 0s 7us/sample - loss: 0.3060 - acc: 0.8567\n",
      "Epoch 11/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3042 - acc: 0.8576\n",
      "Epoch 12/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.3034 - acc: 0.8593\n",
      "Epoch 13/20\n",
      "26048/26048 [==============================] - 0s 7us/sample - loss: 0.3020 - acc: 0.8597\n",
      "Epoch 14/20\n",
      "26048/26048 [==============================] - 0s 8us/sample - loss: 0.2999 - acc: 0.8613\n",
      "Epoch 15/20\n",
      "26048/26048 [==============================] - 0s 9us/sample - loss: 0.3000 - acc: 0.8603\n",
      "Epoch 16/20\n",
      "26048/26048 [==============================] - 0s 7us/sample - loss: 0.2968 - acc: 0.8616\n",
      "Epoch 17/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.2960 - acc: 0.8618\n",
      "Epoch 18/20\n",
      "26048/26048 [==============================] - 0s 7us/sample - loss: 0.2954 - acc: 0.8601\n",
      "Epoch 19/20\n",
      "26048/26048 [==============================] - 0s 8us/sample - loss: 0.2936 - acc: 0.8635\n",
      "Epoch 20/20\n",
      "26048/26048 [==============================] - 0s 6us/sample - loss: 0.2922 - acc: 0.8651\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "### Load\n",
    "models = {}\n",
    "models['dt'] = pickle.load(open('./saved_models/dt.p', 'rb'))\n",
    "models['rfc'] = pickle.load(open('./saved_models/rfc.p', 'rb'))\n",
    "models['nn'] = tf.keras.models.load_model('./saved_models/nn.h5')\n",
    "\n",
    "## Initialise NN output shape as (None, 1) for tensorflow.v1\n",
    "models['nn'].predict(np.zeros((2, 103)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jrhs/miniforge3/envs/tf_mac/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.40039673],\n",
       "       [0.40039673]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "example_data = X_test[0, :].reshape(1,-1)\n",
    "\n",
    "dt_pred = models['dt'].predict(example_data)[0]\n",
    "rfc_pred = models['rfc'].predict(example_data)[0]\n",
    "nn_pred = models['nn'].predict(example_data)[0][0]\n",
    "\n",
    "print(f\"DT [{dt_pred}], RFC [{rfc_pred}], NN [{nn_pred}]\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DT [0], RFC [0], NN [0.5081313848495483]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alibi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Counterfactual Prototype"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "cat_vars_dict = get_cat_vars_dict(scaled_df, categorical_cols, feature_names, target_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "cat_vars_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: 8, 2: 16, 3: 7, 4: 14, 5: 6, 6: 5, 7: 2, 11: 41}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "cat_feature_names = [ col for col in categorical_cols if col != target_name ] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "cat_vars_idx_info = []\n",
    "\n",
    "for cat_col in cat_feature_names:\n",
    "    num_unique_v = len([ col for col in train_df.columns if cat_col in col])\n",
    "    first_index = min([ list(train_df.columns).index(col) for col in train_df.columns if cat_col in col])\n",
    "    \n",
    "    cat_vars_idx_info.append({\n",
    "        \"col\": cat_col,\n",
    "        \"num_unique_v\": num_unique_v,\n",
    "        \"first_index\": first_index\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cat_vars_ohe = {}\n",
    "\n",
    "for idx_info in cat_vars_idx_info:\n",
    "    cat_vars_ohe[idx_info['first_index']] = idx_info['num_unique_v']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "cat_vars_ohe"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{4: 8, 12: 16, 28: 7, 35: 14, 49: 6, 55: 5, 60: 2, 62: 41}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from alibi_cf import AlibiBinaryPredictWrapper"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "alibi_wrapped = {\n",
    "    'dt': AlibiBinaryPredictWrapper(models['dt']),\n",
    "    'rfc': AlibiBinaryPredictWrapper(models['rfc']),\n",
    "    'nn': AlibiBinaryPredictWrapper(models['nn']),\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "feature_range = (np.ones((1, len(feature_names))), np.zeros((1, len(feature_names))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "cf_p_dict = {}\n",
    "\n",
    "for k in alibi_wrapped.keys():\n",
    "    cf_p_dict[k] = CounterFactualProto(\n",
    "                                alibi_wrapped[k].predict,\n",
    "                                example_data.shape,\n",
    "                                cat_vars=cat_vars_ohe,\n",
    "                                feature_range=feature_range,\n",
    "                                max_iterations=500,\n",
    "                                ohe=True,\n",
    "                                )\n",
    "\n",
    "    cf_p_dict[k].fit(X_train)\n",
    "    \n",
    "\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "num_instances = 5\n",
    "num_cf_per_instance = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "results = {}\n",
    "for k in cf_p_dict.keys():\n",
    "    results[k] = []\n",
    "    print(f\"Finding counterfactual for {k}\")\n",
    "    for idx, instance in enumerate(X_test[0:num_instances]):\n",
    "        print(f\"instance {idx}\")\n",
    "        example = instance.reshape(1, -1)\n",
    "        for num_cf in range(num_cf_per_instance):\n",
    "            print(f\"CF {num_cf}\")\n",
    "            start_t = time()\n",
    "            exp = cf_p_dict[k].explain(example)\n",
    "            end_t = time ()\n",
    "            running_time = end_t - start_t\n",
    "\n",
    "            if k=='nn':\n",
    "                prediction = target_label_encoder.inverse_transform((models[k].predict(example)[0]> 0.5).astype(int))[0]\n",
    "            else:\n",
    "                prediction = target_label_encoder.inverse_transform(models[k].predict(example))[0]\n",
    "\n",
    "            if (not exp.cf is None) and (len(exp.cf) > 0):\n",
    "                print(\"Found CF\")\n",
    "                if k == 'nn':\n",
    "                    cf = inverse_dummy(pd.DataFrame(exp.cf['X'], columns=ohe_feature_names), all_cat_ohe_cols)\n",
    "                    cf.loc[0, target_name] = target_label_encoder.inverse_transform([exp.cf['class']])[0]\n",
    "                else:\n",
    "                    cf = inverse_dummy(pd.DataFrame(exp.cf['X'], columns=ohe_feature_names), all_cat_ohe_cols)\n",
    "                    cf.loc[0, target_name] = target_label_encoder.inverse_transform([exp.cf['class']])[0]\n",
    "                # print(exp.cf)\n",
    "                # print(cf)\n",
    "            else:\n",
    "                print(\"CF not found\")\n",
    "                cf = None\n",
    "\n",
    "            input_df = inverse_dummy(pd.DataFrame(example, columns=ohe_feature_names), all_cat_ohe_cols)\n",
    "            input_df.loc[0, target_name] = prediction\n",
    "\n",
    "            results[k].append({\n",
    "                \"input\": input_df,\n",
    "                \"cf\": cf,\n",
    "                'exp': exp,\n",
    "                \"running_time\": running_time,\n",
    "                \"ground_truth\": target_label_encoder.inverse_transform([y_test[idx]])[0],\n",
    "                \"prediction\": prediction,\n",
    "            })"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finding counterfactual for dt\n",
      "instance 0\n",
      "CF 0\n",
      "CF not found\n",
      "instance 1\n",
      "CF 0\n",
      "CF not found\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "Found CF\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n",
      "Finding counterfactual for rfc\n",
      "instance 0\n",
      "CF 0\n",
      "CF not found\n",
      "instance 1\n",
      "CF 0\n",
      "CF not found\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "Found CF\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n",
      "Finding counterfactual for nn\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "CF not found\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "Found CF\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "all_df = {}\n",
    "\n",
    "for k in results.keys():\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i in range(len(results[k])):\n",
    "        final_df = pd.DataFrame([{}])\n",
    "\n",
    "        scaled_input_df = results[k][i]['input'].copy(deep=True)\n",
    "        origin_columns = [f\"origin_input_{col}\"  for col in scaled_input_df.columns]\n",
    "        origin_input_df = scaled_input_df.copy(deep=True)\n",
    "        scaled_input_df.columns = [f\"scaled_input_{col}\"  for col in scaled_input_df.columns]\n",
    "\n",
    "        origin_input_df[numerical_cols] = scaler.inverse_transform(origin_input_df[numerical_cols])\n",
    "        origin_input_df.columns = origin_columns\n",
    "\n",
    "        final_df = final_df.join([scaled_input_df, origin_input_df])\n",
    "\n",
    "        if not results[k][i]['cf'] is None:\n",
    "            scaled_cf_df = results[k][i]['cf'].copy(deep=True)\n",
    "            # scaled_cf_df.loc[0, target_name] = target_label_encoder.inverse_transform([scaled_cf_df.loc[0, target_name]])[0]\n",
    "            origin_cf_columns = [f\"origin_cf_{col}\"  for col in scaled_cf_df.columns]\n",
    "            origin_cf_df = scaled_cf_df.copy(deep=True)\n",
    "            scaled_cf_df.columns = [f\"scaled_cf_{col}\"  for col in scaled_cf_df.columns]\n",
    "\n",
    "            origin_cf_df[numerical_cols] = scaler.inverse_transform(origin_cf_df[numerical_cols])\n",
    "            origin_cf_df.columns = origin_cf_columns\n",
    "\n",
    "            final_df = final_df.join([scaled_cf_df, origin_cf_df])\n",
    "\n",
    "        # final_df = final_df.join([scaled_input_df, origin_input_df, scaled_cf_df, origin_cf_df])\n",
    "        final_df['running_time'] = results[k][i]['running_time']\n",
    "        final_df['Found'] = \"Y\" if not results[k][i]['cf'] is None else \"N\"\n",
    "        final_df['ground_truth'] = results[k][i]['ground_truth'] \n",
    "        final_df['prediction'] = results[k][i]['prediction'] \n",
    "\n",
    "        all_data.append(final_df)\n",
    "\n",
    "    all_df[k] = pd.concat(all_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "for df_k in all_df.keys():\n",
    "    all_df[df_k].to_csv(f\"proto_{df_k}_result.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_mac': conda)"
  },
  "interpreter": {
   "hash": "5c622353f32ef24c8d83e5c3e334107c074e82d7c3e8ca52c56b9fc900ce33e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}