{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from time import time\n",
    "from utils.df_loader import load_adult_df, load_compas_df, load_german_df, load_diabetes_df\n",
    "from utils.preprocessing import inverse_dummy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.preprocessing import preprocess_df\n",
    "from utils.models import train_three_models, evaluation_test, save_three_models, load_three_models\n",
    "from utils.cf_proto import  generate_cf_proto_result, process_result\n",
    "\n",
    "from alibi.explainers import CounterFactualProto\n",
    "from alibi_cf.utils import get_cat_vars_dict\n",
    "from utils.save import save_result_as_csv\n",
    "\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "tf.keras.backend.clear_session()\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False\n",
    "\n",
    "\n",
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF version:  2.4.0-rc0\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset_name = 'diabetes' # [adult, german, compas]\n",
    "\n",
    "if dataset_name == 'adult':\n",
    "    dataset_loading_fn = load_adult_df\n",
    "elif dataset_name == 'german':\n",
    "    dataset_loading_fn = load_german_df\n",
    "elif dataset_name == 'compas':\n",
    "    dataset_loading_fn = load_compas_df\n",
    "elif dataset_name == 'diabetes':\n",
    "    dataset_loading_fn = load_diabetes_df\n",
    "else:\n",
    "    raise Exception(\"Unsupported dataset\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_info = preprocess_df(dataset_loading_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_df, test_df = train_test_split(df_info.dummy_df, train_size=.8, random_state=seed, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X_train = np.array(train_df[df_info.ohe_feature_names])\n",
    "y_train = np.array(train_df[df_info.target_name])\n",
    "X_test = np.array(test_df[df_info.ohe_feature_names])\n",
    "y_test = np.array(test_df[df_info.target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### Train models\n",
    "models = train_three_models(X_train, y_train)\n",
    "save_three_models(models, dataset_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 614 samples\n",
      "Epoch 1/20\n",
      "614/614 [==============================] - 0s 119us/sample - loss: 0.6984 - acc: 0.4055\n",
      "Epoch 2/20\n",
      "614/614 [==============================] - 0s 28us/sample - loss: 0.6878 - acc: 0.6450\n",
      "Epoch 3/20\n",
      "614/614 [==============================] - 0s 18us/sample - loss: 0.6835 - acc: 0.6580\n",
      "Epoch 4/20\n",
      "614/614 [==============================] - 0s 22us/sample - loss: 0.6784 - acc: 0.6580\n",
      "Epoch 5/20\n",
      "614/614 [==============================] - 0s 24us/sample - loss: 0.6729 - acc: 0.6580\n",
      "Epoch 6/20\n",
      "614/614 [==============================] - 0s 37us/sample - loss: 0.6667 - acc: 0.6580\n",
      "Epoch 7/20\n",
      "614/614 [==============================] - 0s 16us/sample - loss: 0.6586 - acc: 0.6580\n",
      "Epoch 8/20\n",
      "614/614 [==============================] - 0s 33us/sample - loss: 0.6502 - acc: 0.6580\n",
      "Epoch 9/20\n",
      "614/614 [==============================] - 0s 26us/sample - loss: 0.6429 - acc: 0.6580\n",
      "Epoch 10/20\n",
      "614/614 [==============================] - 0s 15us/sample - loss: 0.6361 - acc: 0.6580\n",
      "Epoch 11/20\n",
      "614/614 [==============================] - 0s 20us/sample - loss: 0.6289 - acc: 0.6580\n",
      "Epoch 12/20\n",
      "614/614 [==============================] - 0s 24us/sample - loss: 0.6204 - acc: 0.6678\n",
      "Epoch 13/20\n",
      "614/614 [==============================] - 0s 17us/sample - loss: 0.6093 - acc: 0.6938\n",
      "Epoch 14/20\n",
      "614/614 [==============================] - 0s 16us/sample - loss: 0.5936 - acc: 0.6971\n",
      "Epoch 15/20\n",
      "614/614 [==============================] - 0s 16us/sample - loss: 0.5789 - acc: 0.6971\n",
      "Epoch 16/20\n",
      "614/614 [==============================] - 0s 22us/sample - loss: 0.5646 - acc: 0.7068\n",
      "Epoch 17/20\n",
      "614/614 [==============================] - 0s 27us/sample - loss: 0.5461 - acc: 0.7199\n",
      "Epoch 18/20\n",
      "614/614 [==============================] - 0s 28us/sample - loss: 0.5284 - acc: 0.7264\n",
      "Epoch 19/20\n",
      "614/614 [==============================] - 0s 28us/sample - loss: 0.5120 - acc: 0.7476\n",
      "Epoch 20/20\n",
      "614/614 [==============================] - 0s 22us/sample - loss: 0.4986 - acc: 0.7573\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "models = load_three_models(X_train.shape[-1], dataset_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jrhs/miniforge3/envs/tf_mac/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### Print out accuracy on testset.\n",
    "evaluation_test(models, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DT: [0.7727] | RF [0.7987] | NN [0.7662]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Alibi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Counterfactual Prototype"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "num_instances = 5\n",
    "num_cf_per_instance = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "results = generate_cf_proto_result(df_info, train_df, models, num_instances, num_cf_per_instance, X_train, X_test, y_test, max_iters=500)\n",
    "result_dfs = process_result(results, df_info)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finding counterfactual for dt\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "Found CF\n",
      "instance 2\n",
      "CF 0\n",
      "Found CF\n",
      "instance 3\n",
      "CF 0\n",
      "CF not found\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n",
      "Finding counterfactual for rfc\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "CF not found\n",
      "instance 2\n",
      "CF 0\n",
      "Found CF\n",
      "instance 3\n",
      "CF 0\n",
      "CF not found\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n",
      "Finding counterfactual for nn\n",
      "instance 0\n",
      "CF 0\n",
      "Found CF\n",
      "instance 1\n",
      "CF 0\n",
      "CF not found\n",
      "instance 2\n",
      "CF 0\n",
      "CF not found\n",
      "instance 3\n",
      "CF 0\n",
      "CF not found\n",
      "instance 4\n",
      "CF 0\n",
      "CF not found\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "save_result_as_csv(\"proto\", dataset_name, result_dfs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result has been saved to ./results/proto_diabetes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_mac': conda)"
  },
  "interpreter": {
   "hash": "5c622353f32ef24c8d83e5c3e334107c074e82d7c3e8ca52c56b9fc900ce33e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}