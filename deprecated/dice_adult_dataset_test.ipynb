{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from time import time\n",
    "from utils.df_loader import load_adult_df\n",
    "from utils.preprocessing import remove_missing_values, min_max_scale_numerical, inverse_dummy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from alibi.explainers import CounterFactualProto, CounterFactual\n",
    "from alibi_cf.utils import get_cat_vars_dict\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False\n",
    "\n",
    "\n",
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88, got 80\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TF version:  2.4.0-rc0\n",
      "Eager execution enabled:  True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df, feature_names, numerical_cols, categorical_cols, columns_type, target_name, possible_outcomes = load_adult_df()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "scaled_df, scaler = min_max_scale_numerical(df, numerical_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "scaled_df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age         workclass  education      marital-status  \\\n",
       "0  0.301370         State-gov  Bachelors       Never-married   \n",
       "1  0.452055  Self-emp-not-inc  Bachelors  Married-civ-spouse   \n",
       "2  0.287671           Private    HS-grad            Divorced   \n",
       "3  0.493151           Private       11th  Married-civ-spouse   \n",
       "4  0.150685           Private  Bachelors  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male       0.02174   \n",
       "1    Exec-managerial        Husband  White    Male       0.00000   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male       0.00000   \n",
       "3  Handlers-cleaners        Husband  Black    Male       0.00000   \n",
       "4     Prof-specialty           Wife  Black  Female       0.00000   \n",
       "\n",
       "   capital-loss  hours-per-week native-country  class  \n",
       "0           0.0        0.397959  United-States  <=50K  \n",
       "1           0.0        0.122449  United-States  <=50K  \n",
       "2           0.0        0.397959  United-States  <=50K  \n",
       "3           0.0        0.397959  United-States  <=50K  \n",
       "4           0.0        0.397959           Cuba  <=50K  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dummy_df = pd.get_dummies(scaled_df, columns=  [ col for col in categorical_cols if col != target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### We should have this amount of input features.\n",
    "sum([len(scaled_df[col].unique()) for col in categorical_cols if col != target_name]) + len(numerical_cols)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# label_enconded_df, encoder_dict = label_encode(scaled_df, categorical_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "cat_to_ohe_cat = {}\n",
    "for c_col in categorical_cols:\n",
    "    if c_col != target_name:\n",
    "        cat_to_ohe_cat[c_col] = [ ohe_col for ohe_col in dummy_df.columns if ohe_col.startswith(c_col) and ohe_col != target_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ohe_feature_names = [ col for col in dummy_df.columns if col != target_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dummy_df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age  capital-gain  capital-loss  hours-per-week  class  \\\n",
       "0  0.301370       0.02174           0.0        0.397959  <=50K   \n",
       "1  0.452055       0.00000           0.0        0.122449  <=50K   \n",
       "2  0.287671       0.00000           0.0        0.397959  <=50K   \n",
       "3  0.493151       0.00000           0.0        0.397959  <=50K   \n",
       "4  0.150685       0.00000           0.0        0.397959  <=50K   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      0                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-inc  ...  native-country_Portugal  \\\n",
       "0                  0                       0  ...                        0   \n",
       "1                  0                       0  ...                        0   \n",
       "2                  1                       0  ...                        0   \n",
       "3                  1                       0  ...                        0   \n",
       "4                  1                       0  ...                        0   \n",
       "\n",
       "   native-country_Puerto-Rico  native-country_Scotland  native-country_South  \\\n",
       "0                           0                        0                     0   \n",
       "1                           0                        0                     0   \n",
       "2                           0                        0                     0   \n",
       "3                           0                        0                     0   \n",
       "4                           0                        0                     0   \n",
       "\n",
       "   native-country_Taiwan  native-country_Thailand  \\\n",
       "0                      0                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        0   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             1   \n",
       "3                               0                             1   \n",
       "4                               0                             0   \n",
       "\n",
       "   native-country_Vietnam  native-country_Yugoslavia  \n",
       "0                       0                          0  \n",
       "1                       0                          0  \n",
       "2                       0                          0  \n",
       "3                       0                          0  \n",
       "4                       0                          0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# def inverse_dummy(dummy_df, cat_to_ohe_cat):\n",
    "#     not_dummy_df = dummy_df.copy(deep=True)\n",
    "#     for k in cat_to_ohe_cat.keys():\n",
    "#         not_dummy_df[k] = dummy_df[cat_to_ohe_cat[k]].idxmax(axis=1)\n",
    "#         not_dummy_df[k] = not_dummy_df[k].apply(lambda x: x.replace(f'{k}_',\"\"))\n",
    "#         not_dummy_df.drop(cat_to_ohe_cat[k], axis=1, inplace=True)\n",
    "#     return not_dummy_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "inverse_dummy(dummy_df, cat_to_ohe_cat).head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        age  capital-gain  capital-loss  hours-per-week  class  \\\n",
       "0  0.301370       0.02174           0.0        0.397959  <=50K   \n",
       "1  0.452055       0.00000           0.0        0.122449  <=50K   \n",
       "2  0.287671       0.00000           0.0        0.397959  <=50K   \n",
       "3  0.493151       0.00000           0.0        0.397959  <=50K   \n",
       "4  0.150685       0.00000           0.0        0.397959  <=50K   \n",
       "\n",
       "          workclass  education      marital-status         occupation  \\\n",
       "0         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex native-country  \n",
       "0  Not-in-family  White    Male  United-States  \n",
       "1        Husband  White    Male  United-States  \n",
       "2  Not-in-family  White    Male  United-States  \n",
       "3        Husband  Black    Male  United-States  \n",
       "4           Wife  Black  Female           Cuba  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# enconded_df, encoder_dict = label_encode(scaled_df, categorical_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_label_encoder = LabelEncoder()\n",
    "dummy_df[target_name] = target_label_encoder.fit_transform(dummy_df[target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_df, test_df = train_test_split(dummy_df, train_size=.8, random_state=seed, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X_train = np.array(train_df[ohe_feature_names])\n",
    "y_train = np.array(train_df[target_name])\n",
    "X_test = np.array(test_df[ohe_feature_names])\n",
    "y_test = np.array(test_df[target_name])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "### Train\n",
    "nn = model= tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(24,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(12,activation='relu'),\n",
    "                tf.keras.layers.Dense(1),\n",
    "                tf.keras.layers.Activation(tf.nn.sigmoid),\n",
    "            ]\n",
    "        )\n",
    "nn.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn.fit(X_train, y_train, batch_size=64, epochs=20, shuffle=True)\n",
    "\n",
    "models = {\n",
    "    \"dt\": DecisionTreeClassifier().fit(X_train,y_train),\n",
    "    \"rfc\": RandomForestClassifier().fit(X_train,y_train),\n",
    "    \"nn\": nn,\n",
    "}\n",
    "\n",
    "pickle.dump(models['dt'], open('./saved_models/dt.p', 'wb'))\n",
    "pickle.dump(models['rfc'], open('./saved_models/rfc.p', 'wb'))\n",
    "models['nn'].save('./saved_models/nn.h5',overwrite=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "407/407 [==============================] - 0s 446us/step - loss: 0.4766 - accuracy: 0.7755\n",
      "Epoch 2/20\n",
      "407/407 [==============================] - 0s 397us/step - loss: 0.3505 - accuracy: 0.8335\n",
      "Epoch 3/20\n",
      "407/407 [==============================] - 0s 378us/step - loss: 0.3362 - accuracy: 0.8426\n",
      "Epoch 4/20\n",
      "407/407 [==============================] - 0s 400us/step - loss: 0.3238 - accuracy: 0.8501\n",
      "Epoch 5/20\n",
      "407/407 [==============================] - 0s 377us/step - loss: 0.3148 - accuracy: 0.8546\n",
      "Epoch 6/20\n",
      "407/407 [==============================] - 0s 459us/step - loss: 0.3212 - accuracy: 0.8515\n",
      "Epoch 7/20\n",
      "407/407 [==============================] - 0s 391us/step - loss: 0.3105 - accuracy: 0.8558\n",
      "Epoch 8/20\n",
      "407/407 [==============================] - 0s 419us/step - loss: 0.3123 - accuracy: 0.8543\n",
      "Epoch 9/20\n",
      "407/407 [==============================] - 0s 534us/step - loss: 0.3051 - accuracy: 0.8575\n",
      "Epoch 10/20\n",
      "407/407 [==============================] - 0s 552us/step - loss: 0.3048 - accuracy: 0.8565\n",
      "Epoch 11/20\n",
      "407/407 [==============================] - 0s 399us/step - loss: 0.3031 - accuracy: 0.8611\n",
      "Epoch 12/20\n",
      "407/407 [==============================] - 0s 376us/step - loss: 0.3105 - accuracy: 0.8519\n",
      "Epoch 13/20\n",
      "407/407 [==============================] - 0s 380us/step - loss: 0.3053 - accuracy: 0.8575\n",
      "Epoch 14/20\n",
      "407/407 [==============================] - 0s 405us/step - loss: 0.3059 - accuracy: 0.8563\n",
      "Epoch 15/20\n",
      "407/407 [==============================] - 0s 395us/step - loss: 0.3045 - accuracy: 0.8561\n",
      "Epoch 16/20\n",
      "407/407 [==============================] - 0s 377us/step - loss: 0.3008 - accuracy: 0.8576\n",
      "Epoch 17/20\n",
      "407/407 [==============================] - 0s 378us/step - loss: 0.2944 - accuracy: 0.8599\n",
      "Epoch 18/20\n",
      "407/407 [==============================] - 0s 376us/step - loss: 0.2932 - accuracy: 0.8665\n",
      "Epoch 19/20\n",
      "407/407 [==============================] - 0s 379us/step - loss: 0.2938 - accuracy: 0.8621\n",
      "Epoch 20/20\n",
      "407/407 [==============================] - 0s 383us/step - loss: 0.2978 - accuracy: 0.8611\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "### Load\n",
    "models = {}\n",
    "models['dt'] = pickle.load(open('./saved_models/dt.p', 'rb'))\n",
    "models['rfc'] = pickle.load(open('./saved_models/rfc.p', 'rb'))\n",
    "models['nn'] = tf.keras.models.load_model('./saved_models/nn.h5')\n",
    "\n",
    "## Initialise NN output shape as (None, 1) for tensorflow.v1\n",
    "models['nn'].predict(np.zeros((2, X_train.shape[-1])))\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.21752243],\n",
       "       [0.21752243]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "example_data = X_test[0, :].reshape(1,-1)\n",
    "\n",
    "dt_pred = models['dt'].predict(example_data)[0]\n",
    "rfc_pred = models['rfc'].predict(example_data)[0]\n",
    "nn_pred = models['nn'].predict(example_data)[0][0]\n",
    "\n",
    "print(f\"DT [{dt_pred}], RFC [{rfc_pred}], NN [{nn_pred}]\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DT [0], RFC [0], NN [0.46238642930984497]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DiCE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import dice_ml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "scaled_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            age         workclass   education      marital-status  \\\n",
       "0      0.301370         State-gov   Bachelors       Never-married   \n",
       "1      0.452055  Self-emp-not-inc   Bachelors  Married-civ-spouse   \n",
       "2      0.287671           Private     HS-grad            Divorced   \n",
       "3      0.493151           Private        11th  Married-civ-spouse   \n",
       "4      0.150685           Private   Bachelors  Married-civ-spouse   \n",
       "...         ...               ...         ...                 ...   \n",
       "32556  0.136986           Private  Assoc-acdm  Married-civ-spouse   \n",
       "32557  0.315068           Private     HS-grad  Married-civ-spouse   \n",
       "32558  0.561644           Private     HS-grad             Widowed   \n",
       "32559  0.068493           Private     HS-grad       Never-married   \n",
       "32560  0.479452      Self-emp-inc     HS-grad  Married-civ-spouse   \n",
       "\n",
       "              occupation   relationship   race     sex  capital-gain  \\\n",
       "0           Adm-clerical  Not-in-family  White    Male      0.021740   \n",
       "1        Exec-managerial        Husband  White    Male      0.000000   \n",
       "2      Handlers-cleaners  Not-in-family  White    Male      0.000000   \n",
       "3      Handlers-cleaners        Husband  Black    Male      0.000000   \n",
       "4         Prof-specialty           Wife  Black  Female      0.000000   \n",
       "...                  ...            ...    ...     ...           ...   \n",
       "32556       Tech-support           Wife  White  Female      0.000000   \n",
       "32557  Machine-op-inspct        Husband  White    Male      0.000000   \n",
       "32558       Adm-clerical      Unmarried  White  Female      0.000000   \n",
       "32559       Adm-clerical      Own-child  White    Male      0.000000   \n",
       "32560    Exec-managerial           Wife  White  Female      0.150242   \n",
       "\n",
       "       capital-loss  hours-per-week native-country  class  \n",
       "0               0.0        0.397959  United-States  <=50K  \n",
       "1               0.0        0.122449  United-States  <=50K  \n",
       "2               0.0        0.397959  United-States  <=50K  \n",
       "3               0.0        0.397959  United-States  <=50K  \n",
       "4               0.0        0.397959           Cuba  <=50K  \n",
       "...             ...             ...            ...    ...  \n",
       "32556           0.0        0.377551  United-States  <=50K  \n",
       "32557           0.0        0.397959  United-States   >50K  \n",
       "32558           0.0        0.397959  United-States  <=50K  \n",
       "32559           0.0        0.193878  United-States  <=50K  \n",
       "32560           0.0        0.397959  United-States   >50K  \n",
       "\n",
       "[32561 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.136986</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "d = dice_ml.Data(dataframe=scaled_df, continuous_features=numerical_cols, outcome_name=target_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# m = dice_ml.Model(model=models['dt'], backend=\"sklearn\")\n",
    "# exp = dice_ml.Dice(d,m)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "class RecordWrapper():\n",
    "    def __init__(self, model, cat_to_ohe_cat, ohe_feature_names):\n",
    "        self.all_inputs = []\n",
    "        self.model = model\n",
    "        self.cat_to_ohe_cat = cat_to_ohe_cat\n",
    "        self.ohe_feature_names = ohe_feature_names\n",
    "\n",
    "\n",
    "    def dice_to_input(self, input_df):\n",
    "        x = input_df.copy(deep=True)\n",
    "\n",
    "        for k in cat_to_ohe_cat.keys():\n",
    "            for ohe_col in cat_to_ohe_cat[k]:\n",
    "                x[ohe_col] = x[k].apply(lambda v: 1 if v in ohe_col else 0) \n",
    "            x.drop([k], axis=1, inplace=True)\n",
    "            \n",
    "        return np.array(x[ohe_feature_names])\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        self.all_inputs.append(x)\n",
    "        cf_input = self.dice_to_input(x)\n",
    "        return self.model.predict_proba(cf_input)\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.all_inputs.append(x)\n",
    "        cf_input = self.dice_to_input(x)\n",
    "        return self.model.predict(cf_input)\n",
    "\n",
    "class NNRecordWrapper():\n",
    "    def __init__(self, model, cat_to_ohe_cat, ohe_feature_names):\n",
    "        self.all_inputs = []\n",
    "        self.model = model\n",
    "        self.cat_to_ohe_cat = cat_to_ohe_cat\n",
    "        self.ohe_feature_names = ohe_feature_names\n",
    "\n",
    "\n",
    "    def dice_to_input(self, input_df):\n",
    "        x = input_df.copy(deep=True)\n",
    "\n",
    "        for k in cat_to_ohe_cat.keys():\n",
    "            for ohe_col in cat_to_ohe_cat[k]:\n",
    "                x[ohe_col] = x[k].apply(lambda v: 1 if v in ohe_col else 0) \n",
    "            x.drop([k], axis=1, inplace=True)\n",
    "            \n",
    "        return np.array(x[ohe_feature_names])\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.all_inputs.append(x)\n",
    "        cf_input = self.dice_to_input(x)\n",
    "        return self.model.predict(tf.constant(cf_input.astype(float)))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        self.all_inputs.append(x)\n",
    "        cf_input = self.dice_to_input(x)\n",
    "        return self.model.predict(tf.constant(cf_input.astype(float)))\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "all_wrapped_models = {\n",
    "    'dt': RecordWrapper(models['dt'], cat_to_ohe_cat, ohe_feature_names),\n",
    "    'rfc': RecordWrapper(models['rfc'], cat_to_ohe_cat, ohe_feature_names),\n",
    "    'nn': NNRecordWrapper(models['nn'], cat_to_ohe_cat, ohe_feature_names),\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# dt_record = RecordWrapper(models['dt'], cat_to_ohe_cat, ohe_feature_names)\n",
    "# m = dice_ml.Model(model=dt_record, backend=\"sklearn\")\n",
    "# exp = dice_ml.Dice(d,m)\n",
    "# dice_exp = exp.generate_counterfactuals(scaled_df.iloc[1:2], total_CFs=5, desired_class=\"opposite\")\n",
    "# dice_exp.cf_examples_list[0].final_cfs_df.iloc[0][:-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dice_cfs = {\n",
    "    'dt': dice_ml.Dice(d,dice_ml.Model(model=all_wrapped_models['dt'], backend=\"sklearn\")),\n",
    "    'rfc': dice_ml.Dice(d,dice_ml.Model(model=all_wrapped_models['rfc'], backend=\"sklearn\")),\n",
    "    'nn': dice_ml.Dice(d,dice_ml.Model(model=all_wrapped_models['nn'], backend=\"sklearn\"))\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "num_instances = 5\n",
    "num_cf_per_instance = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "results = {}\n",
    "\n",
    "for k in dice_cfs.keys():\n",
    "    results[k] = []\n",
    "    print(f\"Finding counterfactual for {k}\")\n",
    "    for idx, instance in enumerate(scaled_df.iloc[test_df[0:num_instances].index].iloc):\n",
    "        print(f\"instance {idx}\")\n",
    "        for num_cf in range(num_cf_per_instance):\n",
    "            print(f\"CF {num_cf}\")\n",
    "            start_t = time()\n",
    "\n",
    "            input_query = pd.DataFrame([instance.to_dict()])\n",
    "            ground_truth = input_query[target_name][0]\n",
    "            exp = dice_cfs[k].generate_counterfactuals(input_query, total_CFs=1, sample_size=200, desired_class=\"opposite\")\n",
    "\n",
    "            # dice_exp = dice_cfs['nn'].generate_counterfactuals(scaled_df.iloc[1:2], total_CFs=1, desired_class=\"opposite\")\n",
    "            # dice_exp.cf_examples_list[0].final_cfs_df.iloc[0][:-1]\n",
    "\n",
    "            if k=='nn':\n",
    "                prediction = target_label_encoder.inverse_transform((all_wrapped_models[k].predict(input_query)[0]> 0.5).astype(int))[0]\n",
    "            else:\n",
    "                prediction = target_label_encoder.inverse_transform(all_wrapped_models[k].predict(input_query))[0]\n",
    "            \n",
    "            end_t = time ()\n",
    "            running_time = end_t - start_t\n",
    "            results[k].append({\n",
    "                \"input\": input_query,\n",
    "                \"cf\": exp.cf_examples_list[0].final_cfs_df,\n",
    "                \"running_time\": running_time,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"prediction\": prediction,\n",
    "            })"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dice_cfs' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa2d648b9aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdice_cfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finding counterfactual for {k}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dice_cfs' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# scaled_input_df = results['dt'][0]['input'].copy(deep=True)\n",
    "# origin_columns = [f\"origin_input_{col}\"  for col in scaled_input_df.columns]\n",
    "# origin_input_df = scaled_input_df.copy(deep=True)\n",
    "# scaled_input_df.columns = [f\"scaled_input_{col}\"  for col in scaled_input_df.columns]\n",
    "\n",
    "# origin_input_df[numerical_cols] = scaler.inverse_transform(origin_input_df[numerical_cols])\n",
    "# origin_input_df.columns = origin_columns\n",
    "\n",
    "# scaled_cf_df = results['dt'][0]['cf'].copy(deep=True)\n",
    "# scaled_cf_df.loc[0, target_name] = target_label_encoder.inverse_transform([scaled_cf_df.loc[0, target_name]])[0]\n",
    "# origin_cf_columns = [f\"origin_cf_{col}\"  for col in scaled_cf_df.columns]\n",
    "# origin_cf_df = scaled_cf_df.copy(deep=True)\n",
    "# scaled_cf_df.columns = [f\"scaled_cf_{col}\"  for col in scaled_cf_df.columns]\n",
    "\n",
    "# origin_cf_df[numerical_cols] = scaler.inverse_transform(origin_cf_df[numerical_cols])\n",
    "# origin_cf_df.columns = origin_cf_columns\n",
    "\n",
    "# final_df = pd.DataFrame([{}])\n",
    "# final_df = final_df.join([scaled_input_df, origin_input_df, scaled_cf_df, origin_cf_df])\n",
    "# final_df['running_time'] = results['dt'][0]['running_time']\n",
    "# final_df['Found'] = \"Y\" if not results['dt'][0]['cf'] is None else \"N\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "all_df = {}\n",
    "\n",
    "for k in results.keys():\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i in range(len(results[k])):\n",
    "        final_df = pd.DataFrame([{}])\n",
    "\n",
    "        scaled_input_df = results[k][i]['input'].copy(deep=True)\n",
    "        origin_columns = [f\"origin_input_{col}\"  for col in scaled_input_df.columns]\n",
    "        origin_input_df = scaled_input_df.copy(deep=True)\n",
    "        scaled_input_df.columns = [f\"scaled_input_{col}\"  for col in scaled_input_df.columns]\n",
    "\n",
    "        origin_input_df[numerical_cols] = scaler.inverse_transform(origin_input_df[numerical_cols])\n",
    "        origin_input_df.columns = origin_columns\n",
    "\n",
    "        final_df = final_df.join([scaled_input_df, origin_input_df])\n",
    "\n",
    "        if not results[k][i]['cf'] is None:\n",
    "            scaled_cf_df = results[k][i]['cf'].copy(deep=True)\n",
    "            scaled_cf_df.loc[0, target_name] = target_label_encoder.inverse_transform([scaled_cf_df.loc[0, target_name]])[0]\n",
    "            origin_cf_columns = [f\"origin_cf_{col}\"  for col in scaled_cf_df.columns]\n",
    "            origin_cf_df = scaled_cf_df.copy(deep=True)\n",
    "            scaled_cf_df.columns = [f\"scaled_cf_{col}\"  for col in scaled_cf_df.columns]\n",
    "\n",
    "            origin_cf_df[numerical_cols] = scaler.inverse_transform(origin_cf_df[numerical_cols])\n",
    "            origin_cf_df.columns = origin_cf_columns\n",
    "\n",
    "            final_df = final_df.join([scaled_cf_df, origin_cf_df])\n",
    "\n",
    "        # final_df = final_df.join([scaled_input_df, origin_input_df, scaled_cf_df, origin_cf_df])\n",
    "        final_df['running_time'] = results[k][i]['running_time']\n",
    "        final_df['Found'] = \"Y\" if not results[k][i]['cf'] is None else \"N\"\n",
    "        final_df['ground_truth'] = results[k][i]['ground_truth'] \n",
    "        final_df['prediction'] = results[k][i]['prediction'] \n",
    "\n",
    "        all_data.append(final_df)\n",
    "\n",
    "    all_df[k] = pd.concat(all_data)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4e79b3516187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "for df_k in all_df.keys():\n",
    "    all_df[df_k].to_csv(f\"./results/dice_adult_{df_k}_result.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_mac': conda)"
  },
  "interpreter": {
   "hash": "5c622353f32ef24c8d83e5c3e334107c074e82d7c3e8ca52c56b9fc900ce33e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}